{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bongfire/full-stack-professional/blob/main/CapsNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "!pip install optuna"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "FYBOnmTO6nRs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66cf5d9e-39ef-4b1b-ace9-7977a593c1b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-x8RIPWgg8d4"
      },
      "outputs": [],
      "source": [
        "#Cell 1\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, average_precision_score\n",
        "import optuna\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths and hyperparameters\n",
        "#Cell 2\n",
        "dataset_path = '/content/drive/MyDrive/Original Dataset'\n",
        "input_shape = (224, 224, 3)\n",
        "n_classes = 5  # Update this based on your dataset's number of classes"
      ],
      "metadata": {
        "id": "jjJH25Gq0ZU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing functions\n",
        "#Cell 3\n",
        "\n",
        "def resize_images(image, size=(224, 224)):\n",
        "    return cv2.resize(image, size)\n",
        "\n",
        "def normalize_images(image):\n",
        "    normalized = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    return normalized.astype(np.uint8)\n",
        "\n",
        "def detect_contours(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    return contours[0] if contours else None\n",
        "\n",
        "def create_binary_mask(image, contour):\n",
        "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
        "    cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
        "    return cv2.bitwise_and(image, image, mask=mask)\n",
        "\n",
        "def calculate_hu_moments(contour):\n",
        "    moments = cv2.moments(contour)\n",
        "    return cv2.HuMoments(moments).flatten()\n",
        "\n",
        "def preprocess_image(image):\n",
        "    resized_image = resize_images(image)\n",
        "    normalized_image = normalize_images(resized_image)\n",
        "    contour = detect_contours(normalized_image)\n",
        "    if contour is not None:\n",
        "        cropped_image = create_binary_mask(resized_image, contour)\n",
        "        hu_features = calculate_hu_moments(contour)\n",
        "        return cropped_image, hu_features\n",
        "    return resized_image, None"
      ],
      "metadata": {
        "id": "2oCLGwNl0ZGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess dataset\n",
        "#Cell 4\n",
        "processed_images = []\n",
        "hu_features_dataset = []\n",
        "labels = []\n",
        "\n",
        "for idx, disease_folder in enumerate(os.listdir(dataset_path)):\n",
        "    disease_path = os.path.join(dataset_path, disease_folder)\n",
        "    if os.path.isdir(disease_path):\n",
        "        for image_file in os.listdir(disease_path):\n",
        "            image_path = os.path.join(disease_path, image_file)\n",
        "            image = cv2.imread(image_path)\n",
        "            if image is not None:\n",
        "                cropped_image, hu_features = preprocess_image(image)\n",
        "                if cropped_image is not None and hu_features is not None:\n",
        "                    processed_images.append(cropped_image)\n",
        "                    hu_features_dataset.append(hu_features)\n",
        "                    labels.append(idx)\n",
        "\n",
        "# Convert to numpy arrays and one-hot encode labels\n",
        "processed_images = np.array(processed_images)\n",
        "hu_features_dataset = np.array(hu_features_dataset)\n",
        "labels = np.array(labels)\n",
        "y_train_one_hot = tf.keras.utils.to_categorical(labels, num_classes=n_classes)\n",
        "\n",
        "# Split dataset\n",
        "X_train_images, X_test_images, X_train_hu, X_test_hu, y_train, y_test = train_test_split(\n",
        "    processed_images, hu_features_dataset, y_train_one_hot, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "kM5ibp7T0Y2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CapsNet architecture\n",
        "#Cell 5\n",
        "def CapsNet(input_shape, n_classes, n_routing=3):\n",
        "    image_input = layers.Input(shape=input_shape, name=\"Image_Input\")\n",
        "    hu_input = layers.Input(shape=(7,), name=\"Hu_Moments_Input\")\n",
        "\n",
        "    # Convolutional layers\n",
        "    conv1 = layers.Conv2D(256, (9, 9), activation='relu', padding='same', name=\"Conv1\")(image_input)\n",
        "    primary_caps = layers.Conv2D(32 * 8, (9, 9), strides=2, activation='relu', padding='same', name=\"Primary_Caps\")(conv1)\n",
        "    primary_caps = layers.Reshape([-1, 8], name=\"Reshape_Primary\")(primary_caps)\n",
        "\n",
        "    # Digit Capsule layer with dynamic routing\n",
        "    digit_caps = layers.Dense(n_classes, activation='softmax', name=\"Digit_Caps\")(primary_caps)\n",
        "\n",
        "    # Flatten and combine with Hu moments\n",
        "    digit_caps_flat = layers.Flatten(name=\"Flatten_Caps\")(digit_caps)\n",
        "    combined_features = layers.Concatenate(name=\"Combine_Features\")([digit_caps_flat, hu_input])\n",
        "\n",
        "    # Output layer\n",
        "    output = layers.Dense(n_classes, activation='softmax', name=\"Output_Layer\")(combined_features)\n",
        "\n",
        "    model = models.Model(inputs=[image_input, hu_input], outputs=output, name=\"CapsNet_with_Hu\")\n",
        "    return model\n",
        "\n",
        "# Margin loss function\n",
        "def margin_loss(y_true, y_pred):\n",
        "    m_plus = 0.9\n",
        "    m_minus = 0.1\n",
        "    lambda_val = 0.5\n",
        "    L_k = y_true * tf.square(tf.maximum(0., m_plus - y_pred)) + \\\n",
        "          lambda_val * (1 - y_true) * tf.square(tf.maximum(0., y_pred - m_minus))\n",
        "    return tf.reduce_mean(tf.reduce_sum(L_k, axis=1))"
      ],
      "metadata": {
        "id": "cYrR5eyl0YnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter optimization with Optuna\n",
        "#Cell 6\n",
        "def objective(trial):\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
        "    n_routing = trial.suggest_int(\"n_routing\", 2, 5)\n",
        "\n",
        "    # Build and compile CapsNet model with hyperparameters\n",
        "    capsnet_model = CapsNet(input_shape, n_classes, n_routing)\n",
        "    capsnet_model.compile(optimizer=optimizers.Adam(learning_rate),\n",
        "                          loss=margin_loss, metrics=['accuracy'])\n",
        "\n",
        "    history = capsnet_model.fit(\n",
        "        [X_train_images, X_train_hu], y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=10,  # Fewer epochs for hyperparameter search\n",
        "        validation_split=0.2,\n",
        "        verbose=0\n",
        "    )\n",
        "    return history.history['val_accuracy'][-1]\n",
        "\n",
        "# Run optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=10)\n",
        "best_params = study.best_params\n",
        "print(\"Best Hyperparameters:\", best_params)"
      ],
      "metadata": {
        "id": "TWE_iC7n0YW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eace8d4c-4d4e-4708-839e-f2876c2f4f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-07 05:43:10,342] A new study created in memory with name: no-name-1b3d427f-6a49-4b27-b96f-8ea614fae9f4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train final model with best hyperparameters\n",
        "#Cell 7\n",
        "final_model = CapsNet(input_shape, n_classes, best_params[\"n_routing\"])\n",
        "final_model.compile(\n",
        "    optimizer=optimizers.Adam(best_params[\"learning_rate\"]),\n",
        "    loss=margin_loss,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Add early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = final_model.fit(\n",
        "    [X_train_images, X_train_hu], y_train,\n",
        "    batch_size=best_params[\"batch_size\"],\n",
        "    epochs=100,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "bEwJLRy70XdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "#Cell 8\n",
        "y_pred = final_model.predict([X_test_images, X_test_hu])\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_test_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_classes, y_pred_classes))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test_classes, y_pred_classes))\n",
        "print(\"\\nF1-Score:\", f1_score(y_test_classes, y_pred_classes, average='weighted'))\n",
        "print(\"mAP:\", average_precision_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "# Calculate and print FPS\n",
        "start_time = time.time()\n",
        "_ = final_model.predict([X_test_images, X_test_hu])\n",
        "fps = len(X_test_images) / (time.time() - start_time)\n",
        "print(\"\\nFrames Per Second (FPS):\", fps)\n",
        "\n",
        "# Print final accuracy\n",
        "train_acc = history.history['accuracy'][-1]\n",
        "val_acc = history.history['val_accuracy'][-1]\n",
        "test_acc = np.mean(y_pred_classes == y_test_classes)\n",
        "print(\"\\nFinal Training Accuracy:\", train_acc)\n",
        "print(\"Final Validation Accuracy:\", val_acc)\n",
        "print(\"Final Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "id": "MdDSNwD-hhNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "#Cell 9\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d4IMJCwYhhB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "#Cell 10\n",
        "final_model.save(\"optimized_capsnet_model.h5\")\n",
        "\n",
        "# Convert to TensorFlow Lite for mobile deployment\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
        "tflite_model = converter.convert()\n",
        "with open(\"capsnet_model.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "metadata": {
        "id": "igeqJmD2hg49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frames per second (FPS)\n",
        "# Frames per second (FPS)\n",
        "# Frames per second (FPS)\n",
        "# Frames per second (FPS)\n",
        "#Cell 11\n",
        "import time # Import the 'time' module to access its functions\n",
        "\n",
        "start_time = time.time()\n",
        "_ = model.predict([X_test_images, X_test_hu]) # Replace 'capsnet_model' with 'model'\n",
        "fps = len(X_test_images) / (time.time() - start_time)\n",
        "print(\"Frames Per Second (FPS):\", fps)"
      ],
      "metadata": {
        "id": "Lar2h5yit8B9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Vq5Q12-I7hvVeC_30bRgvomBIpryBaXJ",
      "authorship_tag": "ABX9TyN8VPVRen1PGxN2aIKilkOO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}